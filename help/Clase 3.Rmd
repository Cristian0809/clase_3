---
pagetitle: "Clase 3"
autor: Eduard F Martinez-Gonzalez
Nota: En este script no se incluyen acentos ni caracteres especiales para evitar conflictos con otros sistemas operativos.
---
<style type="text/css">
h1 {
  font-size: 32px;
  color: red
}
h1.title {
  font-size: 32px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
p {
 font-size: 16px;
 color: black
}
li {
 font-size: 16px;
 color: black
}
.table th:not([align]) {
  text-align: left;
}
</style>


### En la clase anterior vimos ...

* Manejo de la biblioteca y gestión de paquetes
* Trabajar sobre un directorio de trabajo en R
* Estructuras de datos en R

### Hoy veremos ...

* Importar bases de datos desde diferentes formatos
* Filtrar dataframes (filas y/o columnas)
* "Colapsar" un dataframe
* Exportar bases de datos

# 0. Configuración inicial

#### 0.1 Limpiar la consola, el entorno y fijar directorio de trabajo

```{r setup,include=FALSE}
knitr::opts_chunk$set(warning = T , eval = T , echo = T)
```


```{r}
cat("\f") # Limpiar la consola
rm(list=ls()) # Limpiar el entorno de R
setwd("~/Dropbox/teaching/Taller de R/GitHub/Clases/Clase 3") # Cambiar este directorio
```

#### 0.2 Instalar las librerias que vamos a usar en la clase de hoy
```{r}
for ( paquete in c('tidyverse','readxl','haven') ){
      existe = length(grep(paquete,installed.packages()[,1]))
      if (existe == 0 ){ install.packages(paquete)}
      else {print(paste0('La libreria ' , paquete , ' ya esta instalada.'))}
      rm(paquete,existe)
}
```

#### 0.3 Llamar las librerias
```{r}
library('tidyverse') ; library('readxl') ; library('haven')
```

```tidyverse``` contiene ocho de las libreruas mas empleadas en el analisis cotidiano de bases de datos. A partir de la version ```1.2.0```, ```tidyverse``` contiene los siguientes paquetes: ```ggplot2```, ```dplyr```, ```tidyr```, ```readr```, ```purr```, ```tibble```, ```stringr``` y ```forcats```. Puede obtener mas informacion de ```tidyverse``` [aquí](https://www.tidyverse.org/packages/).







# 1. Importar bases de datos desde diferentes formatos

#### Hint: Funcion %>% (Pipe)
```{r}
c("2","4") %>% as.numeric(.)
c("4","25") %>% as.numeric() %>% sqrt() %>% + 2  
sqrt( as.numeric( c("4","25") ) ) + 2  # Esto es equivalente a la linea anterior
```


#### 1.1. Inspeccionemos las bases de datos en nuestro directorio de trabajo
```{r}
list.files("datos/originales/")
```

#### 1.2.1 Importar bases de datos en formato .csv
```{r}
?read.csv # Obtener ayuda de la funcion
data_csv <- read.csv2(file = 'datos/originales/censo 2018.csv' ,sep = ",", header = TRUE, stringsAsFactors = F)
data_csv = data.frame(data_csv) # Convertir en dataframe
str(data_csv) # Inspeccionar las variables del dataframe

# Podemos cargar y convertir la base de datos en un dataframe en una misma linea (usando el operador Pipe)
data_csv <- read.csv2(file = 'datos/originales/censo 2018.csv' ,sep = ",", header = T, stringsAsFactors = F) %>% data.frame() 
```

#### 1.2.2 Importar bases de datos en formato .xls y .xlsx
```{r}
excel_sheets(path = 'datos/originales/hurto-personas-2020_0.xlsx') # Hojas que contiene el excel 
?read_excel # Obtener ayuda de la funcion
data_xls <- read_excel(path = 'datos/originales/hurto-personas-2020_0.xlsx' , sheet = "Sheet1" , col_names = TRUE) %>% data.frame() 
```

La base de datos de hurtos a personas se obtiene de las estadísticas delictivas procesadas por el GICRI de la Policía Nacional y puede ser descargada [aquí](https://www.policia.gov.co/grupo-información-criminalidad/estadistica-delictiva).

#### 1.2.3 Importar bases de datos en formato .dta
```{r}
?read_dta # Obtener ayuda de la funcion
data_dta <- read_dta(file = 'datos/originales/Area - Caracteristicas generales (Personas).dta')  %>% data.frame() 
```

La base de datos de la Gran Encuesta Integrada de Hogares (GEIH) es recolectada y organizada por el DANE. Los microdatos pueden ser descargados [aquí](https://www.dane.gov.co/index.php/estadisticas-por-tema/mercado-laboral).


#### 1.2.4 Importar bases de datos en formato .rds
```{r}
?readRDS # Obtener ayuda de la funcion
data_rds = readRDS(file = 'datos/originales/proyecciones DANE 2005-2020.rds')  %>% data.frame() 
```

#### 1.2.5 Importar bases de datos en formato .Rdata
```{r}
?load
load(file = 'datos/originales/Homicidios 2020.Rdata')
```










# 2. Filtrar dataframes (filas y/o columnas)

#### 2.1.1 Seleccionar columnas de un dataframe usando los nombre de las variables
```{r}
colnames(data_rdata)

data_rdata_1 = dplyr::select(data_rdata , municipio , `codigo dane` , mes , cantidad) # usar `` cuando hay espacios en los nombres

data_rdata_2 = dplyr::select(data_rdata , -departamento) # Anteponer el - cuando quiero eliminar una variable

data_rdata_3 = data_rdata[,c('municipio' , 'codigo dane' , 'mes' , 'cantidad')] # Usando el vector de los nombres
```

#### 2.1.2 Seleccionar columnas de un dataframe usando la posicion de las columnas
```{r}
colnames(data_rdata)

colnames(data_rdata)[c(2,3,9)]

data_rdata_3 = data_rdata[,c(2,3,9)] # Usando el vector de los nombres
```


#### 2.1.2.1 Veamos la funcion grep
```{r}
grep(pattern = 'la' , x = c('Hola','Pola','Nada','Todo'))

grep(pattern = 'municipio' , x = colnames(data_rdata))

nombres = c( grep(pattern = 'municipio' , x = colnames(data_rdata)) , 
             grep(pattern = 'codigo dane' , x = colnames(data_rdata)) , 
             grep(pattern = 'mes' , x = colnames(data_rdata)) , 
             grep(pattern = 'cantidad' , x = colnames(data_rdata))
            )
```

#### 2.1.2.2 Usemos el vector con la posicion de los nombres
```{r}
data_rdata_4 = data_rdata[,nombres]
```

#### 2.1.2.3 Limpiemos el entorno de los nuevos objetos que creamos
```{r2}
rm(data_rdata_1,data_rdata_2,data_rdata_3,data_rdata_4)

'Revisen en casa esta otra forma de eliminar los objetos que empiezan por data_rdata_ usando la funcion grep'
ls()
grep('data_rdata_',ls())
ls()[grep('data_rdata_',ls())]
rm(list = ls()[grep('data_rdata_',ls())])
```

#### 2.2 Filtrar filas de un dataframe
```{r2}
'Vamos a sellecionar solo algunas columnas del dataframe data_csv'
data_csv = data_csv[,c(2,4,7)]
colnames(data_csv) = c('cod_dane','name_muni','poblacion')
data_csv
```

#### 2.2.1 Usando la posicion de las filas
```{r2}
nrow(data_csv)
nrow(data_csv)-3
41:(nrow(data_csv)-3)
data_csv_1 = data_csv[41:(nrow(data_csv)-3),]
```

#### 2.2.2 Usando los atributos de la variable
```{r2}
data_csv_2 = subset(x = data_csv, subset = is.na(name_muni) == F)

data_csv_3 = subset(x = data_csv, subset = is.na(name_muni) == F  & as.numeric(poblacion) > 100000)

data_csv_4 = subset(x = data_csv, subset = is.na(name_muni) == F) %>% 
             subset(as.numeric(poblacion) > 100000)

data_csv_5 = dplyr::filter(data_csv, name_muni %in% c('Medellín','Barranquilla','Cartagena'))
```


#### 2.2.3 Usando un vector
```{r2}
is.na(data_csv$name_muni) 
data_csv_6 = data_csv[is.na(data_csv$name_muni) == F, ]

data_csv_7 = data_csv[ data_csv$name_muni %in% c('Medellín','Barranquilla','Cartagena') , ]
```

#### 2.2.4 Limpiemos la memoria una vez mas
```{r2}
rm(list = ls()[grep('data_csv_',ls())])
```






# 3 "Colapsar" un dataframe

#### 3.1 Calculos por grupos
```{r2}
'primero aseguremonos que el factor de expancion sea numerico'
is.numeric(data_dta$fex_c_2011)

'numero de encuestados por sexo'
data_dta %>% group_by(P6020) %>% summarise(total = sum(fex_c_2011))

'numero de encuestados por sexo y ciudad'
sexo_area = data_dta %>% group_by(P6020,area) %>% summarise(total = sum(fex_c_2011))
```

#### 3.2 Calculos por grupos aplicando filtros
```{r2}
'media de la educacion y la edad por sexo'
data_dta %>% group_by(P6020) %>% summarise(education = weighted.mean(ESC, fex_c_2011) ,  age = weighted.mean(P6040, fex_c_2011))

'limpiemos la variable primero'
is.numeric(data_dta$ESC)
data_dta %>% subset(is.na(ESC)==F) %>% group_by(P6020) %>% summarise(education = weighted.mean(ESC, fex_c_2011) , 
                                                                     age = weighted.mean(P6040, fex_c_2011))

'Hagamos el calculo solo para bogota'
data_dta %>% subset(is.na(ESC)==F & area == 11) %>% group_by(P6020) %>% summarise(education = weighted.mean(ESC, fex_c_2011) , 
                                                                               age = weighted.mean(P6040, fex_c_2011))
```

















# 4 Exportar bases de datos

#### 4.1.1 Exportar bases de datos en formato .csv
```{r}
?write.csv
write.csv(x = data_csv , file = 'datos/procesados/censo 2018.csv')
```

#### 4.1.2 Exportar bases de datos en formato .xls y .xlsx
```{r}
install.packages("WriteXLS")
WriteXLS::WriteXLS(x = data_xls, ExcelFileName = "datos/procesados/Hurtos 2020.xlsx" , SheetNames =  "Hurtos") 
```

#### 4.1.3 Exportar bases de datos en formato .dta
```{r}
?write_dta
write_dta(data = data_dta ,path = 'datos/procesados/Area - Caracteristicas generales (Personas).dta') 
```

#### 4.1.4 Exportar bases de datos en formato .rds
```{r}
?saveRDS
saveRDS(object = data_rds, file = 'datos/procesados/proyecciones DANE 2005-2020.rds')
```

#### 4.1.5 Importar bases de datos en formato .Rdata
```{r}
?save
save(data_rds,data_dta,data_xls,data_csv,file = 'datos/procesados/Datos.Rdata')
```
